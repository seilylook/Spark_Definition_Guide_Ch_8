{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307f7907-03a8-41a8-a430-b2f1aa19d5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/04 14:01:11 WARN Utils: Your hostname, gimsehyeon-ui-MacBookPro.local resolves to a loopback address: 127.0.0.1; using 172.30.1.89 instead (on interface en0)\n",
      "24/10/04 14:01:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/04 14:01:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"chapter8\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7023dd7b-cc63-4fd5-b722-cb5891f3ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = spark.createDataFrame([\n",
    "    (0, \"Ning Ning\", 0, [100]),\n",
    "    (1, \"Kang hae rin\", 1, [500, 250, 100]),\n",
    "    (2, \"Karina\", 1, [250, 100])\n",
    "]) \\\n",
    ".toDF(\"id\", \"name\", \"graduate_program\", \"spark_status\")\n",
    "\n",
    "graduateProgram = spark.createDataFrame([\n",
    "    (0, \"Masters\", \"School of Information\", \"UC Berkeley\"),\n",
    "    (2, \"Masters\", \"EECS\", \"Harvard\"),\n",
    "    (1, \"Ph D\", \"EECS\", \"MIT\"),\n",
    "]) \\\n",
    ".toDF(\"id\", \"degree\", \"department\", \"school\")\n",
    "\n",
    "sparkStatus = spark.createDataFrame([\n",
    "    (500, \"Vice President\"),\n",
    "    (250, \"PMC Member\"),\n",
    "    (100, \"Contributor\"),\n",
    "]) \\\n",
    ".toDF(\"id\", \"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0863f016-07c1-4c38-986a-6447151b39cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "person.createOrReplaceTempView(\"persion\")\n",
    "graduateProgram.createOrReplaceTempView(\"graduateProgram\")\n",
    "sparkStatus.createOrReplaceTempView(\"sparkStatus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a93afb2-d85f-430f-bbd3-f9ccdc8af36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------------+---------------+\n",
      "| id|        name|graduate_program|   spark_status|\n",
      "+---+------------+----------------+---------------+\n",
      "|  0|   Ning Ning|               0|          [100]|\n",
      "|  1|Kang hae rin|               1|[500, 250, 100]|\n",
      "|  2|      Karina|               1|     [250, 100]|\n",
      "+---+------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf67dfe-1abe-4687-b2a8-db225de0f941",
   "metadata": {},
   "source": [
    "## Inner Join\n",
    "\n",
    "내부 조인은 DataFrame이나 테이블에 존재하는 키를 평가한다. 그리고 TRUE으로 평가되는 로우만 결합한다. 다음은 graduateProgram DataFrame과 person DataFrame을 조인해 새로운 DataFrame을 만드는 예제이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3df45f6c-96a3-4b31-9a09-9bf0135301c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=================(12 + 0) / 12][Stage 4:>                (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|        name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|   Ning Ning|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|Kang hae rin|               1|[500, 250, 100]|  1|   Ph D|                EECS|        MIT|\n",
      "|  2|      Karina|               1|     [250, 100]|  1|   Ph D|                EECS|        MIT|\n",
      "+---+------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joinExpression = person[\"graduate_program\"] == graduateProgram[\"id\"]\n",
    "\n",
    "person.join(graduateProgram, joinExpression).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a52c5-27a1-4529-b5b1-492fa96f5cf9",
   "metadata": {},
   "source": [
    "## Outer Join\n",
    "\n",
    "외부 조인은 DataFrame이나 테이블에 존재하는 키를 평가해 참/거짓으로 평가한 로우를 포함(그리고 조인)한다. 왼쪽이나 오른쪽 DataFrame에 일치하는 로우가 없다면 스파크는 해당 위치에 NULL을 삽입한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af1f7132-38b1-4728-9732-3e5ea8ef35c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  id|        name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+----+------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|   0|   Ning Ning|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|   1|Kang hae rin|               1|[500, 250, 100]|  1|   Ph D|                EECS|        MIT|\n",
      "|   2|      Karina|               1|     [250, 100]|  1|   Ph D|                EECS|        MIT|\n",
      "|NULL|        NULL|            NULL|           NULL|  2|Masters|                EECS|    Harvard|\n",
      "+----+------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(graduateProgram, joinExpression, \"outer\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc145d98-aee1-4ee5-9f3a-0b2bdf7138b4",
   "metadata": {},
   "source": [
    "## Left Outer Join\n",
    "\n",
    "왼쪽 외부 조인은 DataFrame이나 테이블에 존재하는 키를 평가한다. 그리고 왼쪽 DataFrame의 모든 로우와 왼쪽 DataFrame과 일치하는 오른쪽 DataFrame의 로우를 함께 포함한다.\n",
    "\n",
    "오른쪽 DataFrame에 일치하는 로우가 없다면 스파크는 해당 위치에 NULL을 삽입한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e1470d-d645-4135-8312-3661438d1fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+----+------------+----------------+---------------+\n",
      "| id| degree|          department|     school|  id|        name|graduate_program|   spark_status|\n",
      "+---+-------+--------------------+-----------+----+------------+----------------+---------------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|   0|   Ning Ning|               0|          [100]|\n",
      "|  2|Masters|                EECS|    Harvard|NULL|        NULL|            NULL|           NULL|\n",
      "|  1|   Ph D|                EECS|        MIT|   2|      Karina|               1|     [250, 100]|\n",
      "|  1|   Ph D|                EECS|        MIT|   1|Kang hae rin|               1|[500, 250, 100]|\n",
      "+---+-------+--------------------+-----------+----+------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.join(person, joinExpression, \"left_outer\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1503d446-80e4-43d0-942c-dcfd68f6903a",
   "metadata": {},
   "source": [
    "## Right Outer Join\n",
    "\n",
    "오른쪽 외부 조인은 DataFrame이나 테이블에 존재하는 키를 평가한다. 그리고 오른쪽 DataFrame의 모든 로우와 오른쪽 DataFrame과 일치하는 왼쪽 DataFrame의 로우를 함께 포함한다.\n",
    "\n",
    "왼쪽 DataFrame에 일치하는 로우가 없다면 스파크는 해당 위치에 NULL을 삽입한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad8d6780-698c-4b7b-a6df-f59176f129cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  id|        name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+----+------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|   0|   Ning Ning|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|NULL|        NULL|            NULL|           NULL|  2|Masters|                EECS|    Harvard|\n",
      "|   2|      Karina|               1|     [250, 100]|  1|   Ph D|                EECS|        MIT|\n",
      "|   1|Kang hae rin|               1|[500, 250, 100]|  1|   Ph D|                EECS|        MIT|\n",
      "+----+------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.join(graduateProgram, joinExpression, \"right_outer\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ed776d-79f9-4eb3-9417-4511a8751200",
   "metadata": {},
   "source": [
    "## Left Semi Join\n",
    "\n",
    "세미 조인은 오른쪽 DataFrame의 어떤 값도 포함하지 않기 때문에 다른 조인 타입과는 약간 다르다. 단지 두 번째 DataFrame은 값이 존재하는지 확인하기 위해 값만 비교하는 용도로 사용한다. \n",
    "\n",
    "만약 값이 존재한다면 왼쪽 DataFrame에 중복 키가 존재하더라도 해당 로우는 결과에 포함된다. 왼쪽 세미 조인은 기존 조인 기능과는 달리 DataFrame의 필터 정도로 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31deb392-c94e-41b5-a3e1-d302b124d6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------------+\n",
      "| id| degree|          department|           school|\n",
      "+---+-------+--------------------+-----------------+\n",
      "|  0|Masters|School of Informa...|      UC Berkeley|\n",
      "|  1|   Ph D|                EECS|              MIT|\n",
      "|  0|Masters|      Duplicated Row|Duplicated School|\n",
      "+---+-------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gradProgram2 = graduateProgram.union(spark.createDataFrame([\n",
    "    (0, \"Masters\", \"Duplicated Row\", \"Duplicated School\"),\n",
    "]))\n",
    "\n",
    "gradProgram2.createOrReplaceTempView(\"gradProgram2\")\n",
    "\n",
    "gradProgram2.join(person, joinExpression, \"left_semi\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad7a3f-b53a-47bf-80c1-0b802dd94a9b",
   "metadata": {},
   "source": [
    "## Left Anti Join\n",
    "\n",
    "왼쪽 안티 조인은 왼쪽 세미 조인의 반대 개념이다. 왼쪽 세미 조인처럼 오른쪽 DataFrame의 어떤 값도 포함하지 않는다. 단지 두 번째 DataFrame은 값이 존재하는지 확인하기 위해 값만 비교하는 용도로 사용한다.\n",
    "\n",
    "하지만 두 번째 DataFrame에 존재하는 값을 유지하는 대신 두 번째 DataFrame에서 관련된 키를 찾을 수 없는 로우만 결과에 포함한다.\n",
    "\n",
    "안티 조인은 SQL의 NOT IN과 같은 스타일의 필터로 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c615604e-764a-436e-8868-7bd4174b2b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+-------+\n",
      "| id| degree|department| school|\n",
      "+---+-------+----------+-------+\n",
      "|  2|Masters|      EECS|Harvard|\n",
      "+---+-------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.join(person, joinExpression, \"left_anti\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ebd7e-86ab-42e8-ba1e-7cde6070453c",
   "metadata": {},
   "source": [
    "## Natural Join\n",
    "\n",
    "자연조인은 조인하려는 컬럼을 암시적으로 추정한다. 즉, 일치하는 컬럼을 찾고 그 결과를 반환한다. 왼쪽과 오른쪽 그리고 외부 자연 조인을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17cdfed-ae11-4005-8620-5eb92bb282c3",
   "metadata": {},
   "source": [
    "## Cross Join | Cartesian Join\n",
    "\n",
    "교차 조인은 조건절을 기술하지 않은 내부 조인을 의미한다. 교차 조인은 왼쪽 DataFrame의 모든 로우를 오른쪽 DataFrame의 모든 로우와 결합한다. 교차 조인을 거치면 정말 엄청난 수의 로우를 가진 DataFrame이 생성될 수 있다.\n",
    "\n",
    "1000개의 로우가 존재하는 두 개의 DataFrame에 교차 조인을 수행하면 1000000개의 결과 로우가 생성될 수 있다.\n",
    "\n",
    "따라서 반드시 키워드를 사용해 교차 조인을 수행한다는 것을 명시적으로 선언해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efda3b6a-9de5-4184-baa9-c94bf11de093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+---+------------+----------------+---------------+\n",
      "| id| degree|          department|     school| id|        name|graduate_program|   spark_status|\n",
      "+---+-------+--------------------+-----------+---+------------+----------------+---------------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|  0|   Ning Ning|               0|          [100]|\n",
      "|  1|   Ph D|                EECS|        MIT|  1|Kang hae rin|               1|[500, 250, 100]|\n",
      "|  1|   Ph D|                EECS|        MIT|  2|      Karina|               1|     [250, 100]|\n",
      "+---+-------+--------------------+-----------+---+------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.join(person, joinExpression, \"cross\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32512334-196e-4812-85e0-70c69b38ed03",
   "metadata": {},
   "source": [
    "## 복합 데이터 타입의 조인\n",
    "\n",
    "복합 데이터 타입의 조인이 어려워 보이지만 사실 그렇지 않다. 불리언을 반환하는 모든 표현식은 조인 표현식으로 간주할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c66fc3e0-24d6-4153-9590-2626e6e253d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------------+---------------+---+--------------+\n",
      "|personId|        name|graduate_program|   spark_status| id|        status|\n",
      "+--------+------------+----------------+---------------+---+--------------+\n",
      "|       0|   Ning Ning|               0|          [100]|100|   Contributor|\n",
      "|       1|Kang hae rin|               1|[500, 250, 100]|500|Vice President|\n",
      "|       1|Kang hae rin|               1|[500, 250, 100]|250|    PMC Member|\n",
      "|       1|Kang hae rin|               1|[500, 250, 100]|100|   Contributor|\n",
      "|       2|      Karina|               1|     [250, 100]|250|    PMC Member|\n",
      "|       2|      Karina|               1|     [250, 100]|100|   Contributor|\n",
      "+--------+------------+----------------+---------------+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.withColumnRenamed(\"id\", \"personId\") \\\n",
    ".join(sparkStatus, expr(\"array_contains(spark_status, id)\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
